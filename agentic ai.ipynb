{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163c35d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing dataset: imdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\AppData\\Local\\Temp\\ipykernel_48628\\3464753542.py:44: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x) if isinstance(x, dict) else x)\n",
      "C:\\Users\\Nidhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing dataset: emotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\AppData\\Local\\Temp\\ipykernel_48628\\3464753542.py:44: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x) if isinstance(x, dict) else x)\n",
      "C:\\Users\\Nidhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "class ComprehensiveDatasetAnalyzer:\n",
    "    def __init__(self, datasets, model_name=\"distilbert-base-uncased-distilled-squad\"):\n",
    "        \n",
    "        self.datasets = datasets\n",
    "        self.workspace_dir = \"comprehensive_dataset_analysis_workspace\"\n",
    "        os.makedirs(self.workspace_dir, exist_ok=True)\n",
    "        os.makedirs(f\"{self.workspace_dir}/reports\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.workspace_dir}/visualizations\", exist_ok=True)\n",
    "\n",
    "        # Load QA model for text insights\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "        self.qa_pipeline = pipeline(\"question-answering\", model=self.model, tokenizer=self.tokenizer)\n",
    "\n",
    "    def perform_comprehensive_analysis(self):\n",
    "\n",
    "        comprehensive_results = {}\n",
    "\n",
    "        for dataset_name in self.datasets:\n",
    "            try:\n",
    "                print(f\"\\nAnalyzing dataset: {dataset_name}\")\n",
    "                dataset = load_dataset(dataset_name)\n",
    "\n",
    "                # split by keys\n",
    "                split = list(dataset.keys())[0]\n",
    "                data = dataset[split]\n",
    "\n",
    "                # Converting HuggingFace dataset to a Pandas DataFrame\n",
    "                try:\n",
    "                    df = pd.DataFrame(data)\n",
    "                except Exception as e:\n",
    "                    df = pd.DataFrame(data.to_pandas())\n",
    "                \n",
    "                # separate key value by using applymap\n",
    "                df = df.applymap(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "                # Perform analysis\n",
    "                analysis_results = {\n",
    "                    \"exploratory_analysis\": self._perform_exploratory_data_analysis(df),\n",
    "                    \"preprocessing_needs\": self._analyze_preprocessing_needs(df),\n",
    "                    \"text_insights\": self._generate_text_insights(df),\n",
    "                }\n",
    "\n",
    "                # Generate visualizations\n",
    "                analysis_results[\"visualizations\"] = self._generate_visualizations(df, dataset_name)\n",
    "\n",
    "                # Generate reports\n",
    "                self._generate_comprehensive_report(analysis_results, dataset_name)\n",
    "\n",
    "                comprehensive_results[dataset_name] = analysis_results\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {dataset_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "        # Generate a comparative report\n",
    "        self._generate_comparative_report(comprehensive_results)\n",
    "\n",
    "        return comprehensive_results\n",
    "\n",
    "    def _perform_exploratory_data_analysis(self, df):\n",
    "        eda_results = {\n",
    "            \"basic_info\": {\n",
    "                \"total_rows\": len(df),\n",
    "                \"total_columns\": len(df.columns),\n",
    "                \"column_types\": dict(df.dtypes),\n",
    "            },\n",
    "            \"summary_statistics\": {},\n",
    "            \"column_details\": {},\n",
    "        }\n",
    "\n",
    "        # Numeric column analysis\n",
    "        numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            eda_results[\"summary_statistics\"] = df[numeric_cols].describe().to_dict()\n",
    "\n",
    "        #  column analysis for prepreocessing\n",
    "        for column in df.columns:\n",
    "            col_details = {\n",
    "                \"unique_values\": df[column].nunique(),\n",
    "                \"null_count\": df[column].isnull().sum(),\n",
    "                \"null_percentage\": (df[column].isnull().sum() / len(df)) * 100,\n",
    "            }\n",
    "            eda_results[\"column_details\"][column] = col_details\n",
    "\n",
    "        return eda_results\n",
    "\n",
    "    def _analyze_preprocessing_needs(self, df):\n",
    "        \"\"\"Analyze preprocessing requirements.\"\"\"\n",
    "        return {\n",
    "            \"missing_values\": self._detect_missing_values(df),\n",
    "            \"duplicate_rows\": self._detect_duplicate_rows(df),\n",
    "        }\n",
    "\n",
    "    def _detect_missing_values(self, df):\n",
    "        \"\"\"Detect and analyze missing values.\"\"\"\n",
    "        return df.isnull().sum().to_dict()\n",
    "\n",
    "    def _detect_duplicate_rows(self, df):\n",
    "        \"\"\"Detect duplicate rows.\"\"\"\n",
    "        return {\"total_duplicates\": df.duplicated().sum()}\n",
    "\n",
    "    def _generate_text_insights(self, df):\n",
    "        \"\"\"Generate text insights using a QA model.\"\"\"\n",
    "        text_insights = {}\n",
    "        text_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "        for col in text_cols:\n",
    "            try:\n",
    "                text_sample = df[col].dropna().sample(n=1, random_state=1).iloc[0]\n",
    "                if len(str(text_sample)) > 20:  # Ensure valid context\n",
    "                    insights = self.qa_pipeline(\n",
    "                        {\"question\": \"What is the main idea?\", \"context\": text_sample}\n",
    "                    )\n",
    "                    text_insights[col] = insights[\"answer\"]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        return text_insights\n",
    "\n",
    "    def _generate_visualizations(self, df, dataset_name):\n",
    "        \"\"\"Generate visualizations for numeric columns.\"\"\"\n",
    "        viz_files = []\n",
    "        viz_dir = f\"{self.workspace_dir}/visualizations/{dataset_name}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "        for col in numeric_cols:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(df[col], kde=True)\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plot_path = f\"{viz_dir}/{col}_distribution.png\"\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "            viz_files.append(plot_path)\n",
    "\n",
    "        return viz_files\n",
    "\n",
    "    def _generate_comprehensive_report(self, analysis_results, dataset_name):\n",
    "        \"\"\"Generate a comprehensive report for a single dataset.\"\"\"\n",
    "        report_file = f\"{self.workspace_dir}/reports/{dataset_name}_report.txt\"\n",
    "        with open(report_file, \"w\") as f:\n",
    "            for key, value in analysis_results.items():\n",
    "                f.write(f\"{key.upper()}:\\n\")\n",
    "                f.write(f\"{value}\\n\\n\")\n",
    "\n",
    "    def _generate_comparative_report(self, comprehensive_results):\n",
    "        \"\"\"Generate a comparative report across datasets.\"\"\"\n",
    "        comparative_file = f\"{self.workspace_dir}/reports/comparative_report.txt\"\n",
    "        with open(comparative_file, \"w\") as f:\n",
    "            for dataset_name, results in comprehensive_results.items():\n",
    "                f.write(f\"Dataset: {dataset_name}\\n\")\n",
    "                f.write(f\"{results}\\n\\n\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    datasets_to_analyze = [\"imdb\", \"emotion\",'/phihung/titanic']\n",
    "\n",
    "    analyzer = ComprehensiveDatasetAnalyzer(datasets_to_analyze)\n",
    "    results = analyzer.perform_comprehensive_analysis()\n",
    "    print(\"Analysis complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c74114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
